{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D bounding box model\n",
    "\n",
    "In this notebook, we design the model that takes training images and 2D bounding box information and outputs 3D bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements.\n",
    "from data_processing import parse_annotation, data_gen\n",
    "from dataset import TRAIN_KEY, VAL_KEY\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, LeakyReLU, Dropout, Reshape, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants.\n",
    "VGG_INPUT_SHAPE = (224, 224, 3)\n",
    "DIM_OUT_SHAPE = 3\n",
    "ORIENT_OUT_SHAPE = (2, 2)\n",
    "CONF_OUT_SHAPE = 2\n",
    "DEFAULT_MODEL_ARGS = {'input_shape': (224, 224, 3)}\n",
    "DEFAULT_TRAIN_ARGS = {'epochs': 5,\n",
    "                      'batch_size': 32,\n",
    "                      'use_tensorboard': False,\n",
    "                      'model_checkpoint_filename': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientation_loss(y_true, y_pred):\n",
    "        anchors = tf.reduce_sum(tf.square(y_true), axis=2)\n",
    "        anchors = tf.greater(anchors, tf.constant(0.5))\n",
    "        anchors = tf.reduce_sum(tf.cast(anchors, tf.float32), 1)\n",
    "        loss = (y_true[:, :, 0] * y_pred[:, :, 0] + y_true[:, :, 1] * \\\n",
    "                y_pred[:, :, 1])\n",
    "        loss = tf.reduce_sum((2 - 2 * tf.reduce_mean(loss, axis=0))) / anchors\n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_3d_deepbox(vgg_filename) -> keras.Model:\n",
    "    inputs = keras.Input(shape=VGG_INPUT_SHAPE)\n",
    "    x = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    conv5 = Flatten()(x)\n",
    "    dim_out = Dense(512, activation=None)(conv5)\n",
    "    dim_out = LeakyReLU(alpha=0.1)(dim_out)\n",
    "    dim_out = Dropout(rate=0.5)(dim_out)\n",
    "    dim_out = Dense(DIM_OUT_SHAPE, activation=None)(dim_out)\n",
    "    orient_out = Dense(256, activation=None)(conv5)\n",
    "    orient_out = LeakyReLU(alpha=0.1)(orient_out)\n",
    "    orient_out = Dropout(rate=0.5)(orient_out)\n",
    "    orient_out = Dense(ORIENT_OUT_SHAPE[0] * ORIENT_OUT_SHAPE[1], activation=None)(orient_out)\n",
    "    orient_out = Reshape([-1, ORIENT_OUT_SHAPE[0], ORIENT_OUT_SHAPE[1]])(orient_out)\n",
    "    orient_out = Lambda(lambda x: K.l2_normalize(x, axis=2))(orient_out)\n",
    "    conf_out = Dense(256, activation=None)(conv5)\n",
    "    conf_out = LeakyReLU(alpha=0.1)(conf_out)\n",
    "    conf_out = Dropout(rate=0.5)(conf_out)\n",
    "    conf_out = Dense(CONF_OUT_SHAPE, activation=None)(conf_out)\n",
    "    conf_out = Softmax()(conf_out)\n",
    "    model = keras.Model(inputs=inputs, outputs=[dim_out, orient_out, conf_out])\n",
    "    model.compile(loss=[tf.keras.losses.mean_squared_error,\n",
    "                        orientation_loss,\n",
    "                        tf.keras.losses.categorical_crossentropy],\n",
    "                  loss_weights=[4, 8, 1],\n",
    "                  optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: keras.Model, partition, labels, image_dir, label_dir, train_args=DEFAULT_TRAIN_ARGS) -> History:\n",
    "    train_objs = parse_annotation(partition[TRAIN_KEY], label_dir)\n",
    "    val_objs = parse_annotation(partition[VAL_KEY], label_dir)\n",
    "    np.random.shuffle(train_objs)\n",
    "    np.random.shuffle(val_objs)\n",
    "    train_gen = data_gen(image_dir, train_objs, train_args['batch_size'])\n",
    "    val_gen = data_gen(image_dir, val_objs, train_args['batch_size'])\n",
    "    train_steps = int(np.ceil(len(train_objs) / train_args['batch_size']))\n",
    "    val_steps = int(np.ceil(len(val_objs) / train_args['batch_size']))\n",
    "    callbacks = []\n",
    "    if train_args['use_tensorboard']:\n",
    "        log_dir = 'logs_{0}'.format(datetime.now())\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "        callbacks.append(tensorboard_callback)\n",
    "    if train_args['model_checkpoint_filename']:\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            train_args['model_checkpoint_filename'],\n",
    "            save_best_only=True)\n",
    "        callbacks.append(checkpoint_callback) \n",
    "    return model.fit(\n",
    "        x=train_gen,\n",
    "        epochs=train_args['epochs'],\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_gen,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, partition, labels, image_dir) -> Dict[str, Any]:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_paths):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4bai-project",
   "language": "python",
   "name": "4bai-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
